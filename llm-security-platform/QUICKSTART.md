# üöÄ Guide de D√©marrage Rapide - LLM Security Platform Phase 1

## Installation en 5 minutes

### Option 1 : Installation automatique (Recommand√©)

```bash
# 1. Cloner le repository
git clone <repo-url>
cd llm-security-platform

# 2. Ex√©cuter le script d'installation
python install_phase1.py

# 3. Suivre les instructions √† l'√©cran
```

### Option 2 : Installation manuelle

```bash
# 1. Installer les d√©pendances
pip install -r requirements.txt
pip install -r orchestrator/requirements.txt
pip install -r analyzer/requirements.txt

# 2. Cr√©er les r√©pertoires
mkdir -p logs/immutable logs/rbac_audit results runner_results

# 3. Configurer les variables d'environnement
cp .env.example .env
# √âditer .env avec vos param√®tres
```

---

## Configuration minimale

### 1. Endpoint LLM

√âditez `.env`:

```bash
LLM_SECURITY_LLM_ENDPOINT=http://localhost:11434
LLM_SECURITY_LLM_MODEL=llama2
```

### 2. D√©marrer LM Studio

1. T√©l√©charger [LM Studio](https://lmstudio.ai/)
2. Charger un mod√®le (ex: llama2, mistral)
3. D√©marrer le serveur local (port 11434)

---

## Premier scan en 3 commandes

```bash
# 1. Aller dans le r√©pertoire orchestrator
cd orchestrator

# 2. Ex√©cuter un scan
python orchestrator.py "You are a helpful AI assistant"

# 3. Analyser les r√©sultats
cd ../analyzer
python analyzer.py ../orchestrator/results/security_analysis_*.json
```

**R√©sultat attendu :**
- Score global de s√©curit√© (0-10)
- VulnerabilityIndex (0-1)
- Liste des vuln√©rabilit√©s d√©tect√©es
- Recommandations de rem√©diation

---

## Test rapide de validation

```bash
# Ex√©cuter le script de test
python quick_test.py
```

Ce script valide :
- ‚úÖ Imports des modules
- ‚úÖ Configuration
- ‚úÖ Orchestrateur
- ‚úÖ Ex√©cution d'un scan
- ‚úÖ Analyse et scoring
- ‚úÖ Logger immuable
- ‚úÖ RBAC
- ‚úÖ Secrets Manager
- ‚úÖ Sauvegarde des r√©sultats

---

## Utilisation de base

### Scan simple

```bash
cd orchestrator
python orchestrator.py "Your test prompt"
```

### Scan avec configuration personnalis√©e

```bash
python orchestrator.py "Test prompt" --config ../config.yaml
```

### Analyse des r√©sultats

```bash
cd analyzer
python analyzer.py ../orchestrator/results/security_analysis_20241014_120000.json
```

### Export CSV

Les r√©sultats sont automatiquement export√©s en CSV dans `./results/`

---

## D√©ploiement Docker (Optionnel)

### Build et d√©marrage

```bash
cd runners
docker build -t llm-security-runner:latest -f Dockerfile ..
docker-compose up -d
```

### V√©rification

```bash
docker-compose logs -f runner-1
docker-compose ps
```

### Arr√™t

```bash
docker-compose down
```

---

## Configuration avanc√©e (Optionnel)

### Activer l'alerting JIRA

```bash
# Dans .env
LLM_SECURITY_JIRA_URL=https://your-jira.atlassian.net
LLM_SECURITY_JIRA_USERNAME=your-email@example.com
LLM_SECURITY_JIRA_API_TOKEN=your-api-token
LLM_SECURITY_JIRA_PROJECT_KEY=SEC
```

```yaml
# Dans config.yaml
alerting:
  enabled: true
  channels:
    jira:
      enabled: true
```

### Activer Teams/Slack

```bash
# Dans .env
LLM_SECURITY_TEAMS_WEBHOOK_URL=https://outlook.office.com/webhook/...
LLM_SECURITY_SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...
```

### Utiliser Azure Key Vault

```bash
# Installer les d√©pendances
pip install azure-keyvault-secrets azure-identity

# Dans config.yaml
security:
  secrets:
    backend: "azure_keyvault"
    vault_url: "https://your-vault.vault.azure.net/"
```

---

## Structure des r√©sultats

### Fichier JSON

```json
{
  "timestamp": "2024-10-14T12:00:00",
  "model_name": "llama2",
  "overall_score": 7.5,
  "vulnerability_index": 0.35,
  "risk_level": "medium",
  "priority": "P3",
  "tests": {
    "prompt_injection": {
      "score": 8.2,
      "vulnerabilities": []
    },
    "extraction_probe": {
      "score": 6.8,
      "vulnerabilities": [...]
    }
  },
  "vulnerabilities": [...],
  "recommendations": [...]
}
```

### Fichier CSV

| Colonne | Description |
|---------|-------------|
| model_name | Nom du mod√®le test√© |
| timestamp | Date et heure du scan |
| vulnerability_index | Indice de vuln√©rabilit√© (0-1) |
| criticality | Niveau de criticit√© |
| priority | Priorit√© (P1-P5) |
| total_vulnerabilities | Nombre total de vuln√©rabilit√©s |
| critical_vulnerabilities | Nombre de vuln√©rabilit√©s critiques |

---

## Commandes utiles

### V√©rifier la configuration

```bash
python -c "
import yaml
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)
    print(f'Tests activ√©s: {sum(1 for t in config[\"tests\"].values() if t.get(\"enabled\"))}')
"
```

### V√©rifier l'int√©grit√© des logs

```python
from logger.immutable_logger import SecurityAuditLogger

audit_logger = SecurityAuditLogger()
verification = audit_logger.verify_integrity()
print(f"Logs valides: {verification['valid']}")
```

### Lister les utilisateurs RBAC

```python
from security.rbac import RBACManager

rbac = RBACManager("security/rbac_config.json")
users = rbac.list_users()
for user in users:
    print(f"{user['username']}: {user['role']}")
```

---

## D√©pannage rapide

### Probl√®me : LM Studio non accessible

```bash
# V√©rifier que le serveur est d√©marr√©
curl http://localhost:11434/api/tags

# Si erreur, v√©rifier le port dans config.yaml
```

### Probl√®me : Timeout des tests

```yaml
# Dans config.yaml, augmenter le timeout
llm:
  timeout: 60  # Au lieu de 30
```

### Probl√®me : Erreurs d'import

```bash
# R√©installer les d√©pendances
pip install --force-reinstall -r requirements.txt
```

### Probl√®me : Permissions des fichiers

```bash
# Windows PowerShell
icacls logs /grant Everyone:F /T
icacls results /grant Everyone:F /T

# Linux/Mac
chmod -R 755 logs/ results/
```

---

## Prochaines √©tapes

1. **Tester avec vos mod√®les**
   - Configurer votre endpoint LLM
   - Ex√©cuter des scans sur vos mod√®les

2. **Configurer l'alerting**
   - Activer JIRA/Teams/Slack
   - D√©finir les seuils d'alerte

3. **D√©ployer en production**
   - Utiliser les runners Docker
   - Configurer le pipeline CI/CD

4. **Explorer la documentation**
   - [PHASE1_DEPLOYMENT_GUIDE.md](PHASE1_DEPLOYMENT_GUIDE.md) - Guide complet
   - [PHASE1_COMPLETION_SUMMARY.md](PHASE1_COMPLETION_SUMMARY.md) - R√©sum√© Phase 1
   - [README.md](README.md) - Documentation g√©n√©rale

---

## Support

- **Documentation** : Voir les fichiers MD du projet
- **Issues** : GitHub Issues pour les bugs
- **Questions** : Discussions GitHub

---

## Ressources

- [LM Studio](https://lmstudio.ai/) - Endpoint LLM local
- [Azure Key Vault](https://azure.microsoft.com/en-us/services/key-vault/) - Gestion des secrets
- [HashiCorp Vault](https://www.vaultproject.io/) - Alternative pour secrets
- [JIRA](https://www.atlassian.com/software/jira) - Ticketing
- [Microsoft Teams](https://www.microsoft.com/en-us/microsoft-teams/) - Alertes
- [Slack](https://slack.com/) - Alertes

---

**üéâ Vous √™tes pr√™t √† scanner vos mod√®les LLM !**

Pour une documentation compl√®te, consultez [PHASE1_DEPLOYMENT_GUIDE.md](PHASE1_DEPLOYMENT_GUIDE.md)
