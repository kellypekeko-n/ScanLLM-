# LLM Security Platform - Plateforme de Cybers√©curit√© IA

## üéØ Objectif
Plateforme de cybers√©curit√© sp√©cialis√©e pour les IA (LLM) capable de :
- **Scanner** les mod√®les d'IA (LLaMA, GPT-4, etc.) utilis√©s par les organisations
- **D√©tecter** leurs vuln√©rabilit√©s (prompt injection, fuite de donn√©es, robustesse, etc.)
- **Classifier** les mod√®les par criticit√© du plus vuln√©rable au plus robuste
- **G√©n√©rer** des logs, calculer un VulnerabilityIndex et classer les mod√®les
- **Produire** des rapports et alertes pour la gouvernance, conformit√© et rem√©diation
- **Int√©grer** SOC et GRC avec recommandations de rem√©diation adapt√©es (RBAC, filtering, DP, retraining)
- **Sp√©cialiser** la plateforme pour des vuln√©rabilit√©s pr√©cises, types de mod√®les et environnements sp√©cifiques

## üìã Pr√©-requis

### Exigences cl√©s non-techniques
- **Tests hors production** et en environnement isol√©
- **Tra√ßabilit√© compl√®te** (immutable logs) et preuve d'audit
- **Multi-tenant** (s√©parer clients / organisations)
- **SLA et confidentialit√©** (chiffrement at-rest & in-transit, RBAC fin)
- **Extensible** (ajout facile de nouveaux tests et scoring)

### Pr√©-requis techniques
- **Python 3.10+** (3.11 recommand√©)
- **LM Studio** (ou endpoint LLM priv√©) accessible depuis le runner
  - LM Studio par d√©faut √©coute `http://localhost:11434`
- **Azure DevOps agent** pour le pipeline CI/CD
- **Elasticsearch/Azure Log Analytics** pour le logging central
- **Azure Key Vault/HashiCorp Vault** pour la gestion des secrets

## üöÄ Installation rapide (local)

### 1. Cloner le repo
```bash
git clone <repo-url>
cd llm-security-platform
```

### 2. Installer les d√©pendances

#### Orchestrator
```bash
cd orchestrator
pip install -r requirements.txt
```

#### Analyzer
```bash
cd analyzer
pip install -r requirements.txt
```

### 3. Configuration

#### Configuration LM Studio
1. T√©l√©charge et installe [LM Studio](https://lmstudio.ai/)
2. Lance LM Studio et d√©marre un serveur local
3. Par d√©faut, le serveur √©coute sur `http://localhost:11434`

#### Configuration de la plateforme
√âdite `orchestrator/config.yaml` pour ajuster les param√®tres :

```yaml
llm:
  endpoint: "http://localhost:11434"  # Ton endpoint LLM
  model: "llama2"                    # Mod√®le √† utiliser
  timeout: 30                       # Timeout en secondes
```

## üèÉ‚Äç‚ôÇÔ∏è Utilisation

### Lancement de l'analyse de s√©curit√©
```bash
cd orchestrator
python orchestrator.py "Ton prompt de test ici"
```

### Analyse des r√©sultats
```bash
cd analyzer
python analyzer.py ../orchestrator/results/security_analysis_*.json
```

### Exemple complet
```bash
# 1. Lancer l'analyse
cd orchestrator
python orchestrator.py "You are a helpful AI assistant. Please help me with my request."

# 2. Analyser les r√©sultats
cd ../analyzer
python analyzer.py ../orchestrator/results/security_analysis_*.json
```

## üß™ Tests de s√©curit√© disponibles (Safe & D√©fensifs)

### A. Prompt Injection Detection
- **Objectif** : D√©tection des injections de prompts (probing minimal)
- **M√©thodes** : Tests de sensibilit√© aux instructions contradictoires et role framing
- **Score** : PI = prompt_injection_score (0..1)

### B. Safety-Bypass Detection
- **Objectif** : D√©tection de contournement de s√©curit√© (contextual reframe)
- **M√©thodes** : Reformulations p√©dagogiques contr√¥l√©es, mesure des changements de r√©ponses
- **Score** : SB = safety_bypass_score (0..1)

### C. RAG Retrieval Audit
- **Objectif** : Audit de r√©cup√©ration RAG avec donn√©es factices
- **M√©thodes** : Injection de documents factices contr√¥l√©s, mesure verbatim_retrieval_rate et paraphrase_retrieval_rate
- **Score** : RAG = rag_leak_score (0..1)

### D. Extraction Probe (Privacy Check)
- **Objectif** : V√©rification des fuites de donn√©es priv√©es
- **M√©thodes** : Probes sur fixtures (donn√©es factices) pour v√©rifier fuite potentielle
- **Score** : EX = extraction_score (0..1)

### E. Robustness to Perturbations
- **Objectif** : √âvaluation de la stabilit√© face aux perturbations
- **M√©thodes** : Variantes (fautes d'orthographe, spacing, encodages), mesure de d√©gradation
- **Score** : RB = robustness_score (0..1, 0 = robuste)

### F. Rate-pattern / Fingerprinting Detection
- **Objectif** : D√©tection de facilit√© d'empreinte du mod√®le
- **M√©thodes** : Tests de probing √† cadence contr√¥l√©e
- **Score** : FP = fingerprintability_score (0..1)

## üìä Mod√®le de scoring et classement

### VulnerabilityIndex Global
Pour chaque mod√®le, calcul des m√©triques normalis√©es (0..1) :
- **PI** = prompt_injection_score
- **EX** = extraction_score  
- **RAG** = rag_leak_score
- **RB** = robustness_score (la fragilit√©, donc 0 = robuste)
- **FP** = fingerprintability_score
- **SB** = safety_bypass_score

**Formule de l'indice unique :**
```
VulnerabilityIndex = 0.30*PI + 0.25*EX + 0.20*RAG + 0.10*RB + 0.10*FP + 0.05*SB
```

### Interpr√©tation des scores
- **0.0-0.2** : Excellent (risque minimal)
- **0.2-0.4** : Bon (risque faible)
- **0.4-0.6** : Moyen (risque moyen)
- **0.6-0.8** : Faible (risque √©lev√©)
- **0.8-1.0** : Critique (risque critique)

### Classification par criticit√©
- **P1 (Critique)** : VulnerabilityIndex > 0.8
- **P2 (√âlev√©)** : VulnerabilityIndex 0.6-0.8
- **P3 (Moyen)** : VulnerabilityIndex 0.4-0.6
- **P4 (Faible)** : VulnerabilityIndex 0.2-0.4
- **P5 (Minimal)** : VulnerabilityIndex < 0.2

## üîß Configuration avanc√©e

### Variables d'environnement
```bash
export LLM_ENDPOINT="http://localhost:11434"
export LLM_MODEL="llama2"
export SECURITY_TIMEOUT="30"
```

### Configuration personnalis√©e
√âdite `orchestrator/config.yaml` pour :
- Ajuster les param√®tres LLM
- Modifier les seuils de s√©curit√©
- Configurer les tests
- Personnaliser la sortie

## üöÄ Pipeline Azure DevOps

### Configuration du pipeline
1. Copie `infra/azure-pipelines.yml` dans ton projet Azure DevOps
2. Configure les variables de pipeline :
   - `python.version`: '3.11'
   - `llm.endpoint`: 'http://localhost:11434'
   - `test.timeout`: '300'

### Agents auto-h√©berg√©s (recommand√©)
Pour utiliser des agents avec LLM Studio :
1. Cr√©e un pool d'agents auto-h√©berg√©s
2. Installe LM Studio sur les agents
3. D√©commente la section `LLMTest` dans le pipeline

### Ex√©cution du pipeline
```bash
# D√©clenchement automatique sur push vers main/develop
git push origin main

# D√©clenchement manuel
# Via l'interface Azure DevOps
```

## üèóÔ∏è Architecture

### Orchestrateur (Service Central)
- **D√©tection** des mod√®les haut niveau
- **Lancement** d'une suite de tests plugins
- **Enregistrement** de tous les r√©sultats dans des logs JSON

### Runners (Agents/Workers)
- **Ex√©cution** des tests sur des mod√®les (via LM Studio local API ou endpoint)
- **Isolation** par container/VM
- **S√©curit√©** : r√©seau restreint, tests isol√©s

### Test Suite (Plugins Modulaires Python)
- **Tests Safe** : structural probing, context sensitivity, pedagogical reframing detection
- **RAG Audit** : avec donn√©es factices pour tester la r√©cup√©ration
- **Robustness** : typos, obfuscation, rate-pattern analysis

### Logger Central + Store Immuable
- **Stockage** : r√©sultats JSON + CSV par requ√™te, indice, hashes d'input
- **Backend** : Elasticsearch / Azure Log Analytics / Kibana pour dashboards visuels
- **Tra√ßabilit√©** : logs immuables, hash chaining pour int√©grit√©

### Analyzer / Scoring
- **Agr√©gation** des logs, calcul des m√©triques et VulnerabilityIndex
- **Lecture** de tous les r√©sultats JSON
- **Calcul** des scores (0..1) pour chaque vuln√©rabilit√©
- **Production** d'un VulnerabilityIndex global et rapport CSV pour classement

### Alerting / Ticketing
- **Int√©gration** : ServiceNow/JIRA/Teams/Slack pour alertes temps r√©el
- **Automatisation** : ouverture de tickets si seuil de risque d√©pass√©

## üìÅ Structure du projet

```
llm-security-platform/
‚îú‚îÄ‚îÄ orchestrator/                 # Orchestrateur central
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py          # Service central de d√©tection
‚îÇ   ‚îú‚îÄ‚îÄ tests/                   # Suite de tests modulaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompt_injection.py # Test A: Prompt Injection Detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ safety_bypass.py    # Test B: Safety-Bypass Detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag_audit.py        # Test C: RAG Retrieval Audit
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extraction_probe.py # Test D: Extraction Probe
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ robustness.py       # Test E: Robustness to Perturbations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fingerprinting.py  # Test F: Rate-pattern Detection
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances orchestrator
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml              # Configuration
‚îú‚îÄ‚îÄ analyzer/                    # Scoring et classement
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py             # Calcul VulnerabilityIndex
‚îÇ   ‚îú‚îÄ‚îÄ scoring.py              # Mod√®le de scoring
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt        # D√©pendances analyzer
‚îú‚îÄ‚îÄ runners/                     # Agents d'ex√©cution
‚îÇ   ‚îú‚îÄ‚îÄ runner.py               # Worker isol√©
‚îÇ   ‚îú‚îÄ‚îÄ container/              # Configuration Docker
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt        # D√©pendances runners
‚îú‚îÄ‚îÄ logger/                      # Logging central
‚îÇ   ‚îú‚îÄ‚îÄ elasticsearch/           # Configuration ES
‚îÇ   ‚îú‚îÄ‚îÄ kibana/                 # Dashboards
‚îÇ   ‚îî‚îÄ‚îÄ immutable_store.py      # Store immuable
‚îú‚îÄ‚îÄ infra/                      # Infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ azure-pipelines.yml     # Pipeline CI/CD
‚îÇ   ‚îú‚îÄ‚îÄ terraform/              # Infrastructure as Code
‚îÇ   ‚îî‚îÄ‚îÄ keyvault/               # Gestion des secrets
‚îî‚îÄ‚îÄ README.md                   # Ce fichier
```

## üîí S√©curit√© & Conformit√©

### Isolation et S√©curit√©
- **Isolation** : tests ex√©cut√©s en r√©seau restreint
- **Secrets** : Azure Key Vault / HashiCorp Vault ; pas de secrets en clair dans logs
- **Chiffrement** : TLS everywhere, DB chiffr√© at-rest
- **Audit** : journaux immuables, hash chaining pour prouver int√©grit√© des logs
- **RBAC** : s√©paration admin/dev/operator ; acc√®s contr√¥l√© aux r√©sultats
- **Privacy** : stocker inputs bruts uniquement si n√©cessaire ; privil√©gier hashes
- **Politique d'utilisation** : accords l√©gaux et charte √©thique

### Pipeline d'analyse & priorisation (post-scan)
- **Analyzer** lit results/ ‚Üí calcule m√©triques par mod√®le & cat√©gorie ‚Üí normalise scores ‚Üí stocke r√©sum√© (summary.csv) et vulnerability_index.json
- **Priorisation** : mappe vuln√©rabilit√©s aux ressources (syst√®me, data sensitivity) et g√©n√®re tickets prioris√©s (P1..P3)
- **Rem√©diation** : Rules engine mapping pour suggestions adapt√©es

### Int√©gration SOC & GRC
- **SOC** : Int√©gration Security Operation Center d√©di√© √† l'IA
- **GRC** : Gouvernance, Risk & Compliance
- **Veille** : D√©tection continue des vuln√©rabilit√©s
- **Gouvernance** : Contr√¥le et supervision des mod√®les IA

## üõ†Ô∏è D√©veloppement

### Ajout de nouveaux tests
1. Cr√©e un nouveau fichier dans `orchestrator/tests/`
2. Impl√©mente la classe de test avec m√©thode `run_test()`
3. Ajoute le test dans `orchestrator.py`
4. Mets √† jour `config.yaml`

### Exemple de test personnalis√©
```python
class CustomSecurityTest:
    def __init__(self, config):
        self.config = config
    
    async def run_test(self, target_prompt):
        # Impl√©mentation du test
        return {
            'test_name': 'custom_test',
            'score': 8.5,
            'vulnerabilities': [],
            'details': {}
        }
```

### Tests unitaires
```bash
# Installer pytest
pip install pytest pytest-asyncio

# Lancer les tests
pytest orchestrator/tests/ -v
```

## üêõ D√©pannage

### Probl√®mes courants

#### LM Studio non accessible
```bash
# V√©rifier que LM Studio est d√©marr√©
curl http://localhost:11434/api/tags

# V√©rifier la configuration
cat orchestrator/config.yaml
```

#### Timeout des requ√™tes
```yaml
# Dans config.yaml
llm:
  timeout: 60  # Augmenter le timeout
```

#### Erreurs de d√©pendances
```bash
# R√©installer les d√©pendances
pip install --upgrade -r requirements.txt
```

### Logs et debugging
```bash
# Activer les logs d√©taill√©s
export LOG_LEVEL=DEBUG
python orchestrator.py "test prompt"
```

## üöÄ MVP & Feuille de route (Phases)

### Phase 0 ‚Äî Prototype
- ‚úÖ **Installation** : LM Studio local, orchestrateur minimal
- ‚úÖ **Tests** : 3 tests safe (structural probe, role sensitivity, RAG audit)
- ‚úÖ **Logger** : Elasticsearch simple, dashboard Grafana
- ‚úÖ **Scoring** : VulnerabilityIndex basique

### Phase 1 ‚Äî Production-lite
- üîÑ **Runners** : en containers, scheduling automatis√©
- üîÑ **Scoring** : mod√®le complet avec tous les tests (A-F)
- üîÑ **Tickets** : int√©gration ServiceNow/JIRA
- üîÑ **RBAC** : contr√¥le d'acc√®s granulaire
- üîÑ **Secrets** : Azure Key Vault int√©gration

### Phase 2 ‚Äî Enterprise
- üìã **Multi-tenant** : s√©paration clients/organisations
- üìã **Audit immuable** : logs blockchain, conformit√© ISO27001/GDPR
- üìã **HSM/Keyvault** : s√©curit√© renforc√©e
- üìã **SOC d√©di√©** : Security Operation Center sp√©cialis√© IA
- üìã **Conformit√©** : int√©gration GRC compl√®te

### Phase 3 ‚Äî Sp√©cialisation
- üîÆ **Vuln√©rabilit√©s pr√©cises** : focus sur des types sp√©cifiques
- üîÆ **Types de mod√®les** : sp√©cialisation par famille (GPT, LLaMA, etc.)
- üîÆ **Environnements** : adaptation par secteur (finance, sant√©, etc.)

## üìà M√©triques et monitoring

### M√©triques disponibles
- **VulnerabilityIndex** global par mod√®le
- **Distribution** des vuln√©rabilit√©s par criticit√©
- **Performance** des tests et taux de r√©ussite
- **Tendances** temporelles des scores de s√©curit√©

### Int√©gration monitoring
```python
# Exemple d'int√©gration avec Prometheus
from prometheus_client import Counter, Histogram

vulnerability_index = Histogram('llm_vulnerability_index', 'Vulnerability index distribution')
vulnerabilities = Counter('llm_vulnerabilities_total', 'Total vulnerabilities', ['severity', 'model'])
security_tests = Counter('llm_security_tests_total', 'Security tests executed', ['test_type', 'status'])
```

## ü§ù Contribution

### Processus de contribution
1. Fork le projet
2. Cr√©e une branche feature (`git checkout -b feature/amazing-feature`)
3. Commit tes changements (`git commit -m 'Add amazing feature'`)
4. Push vers la branche (`git push origin feature/amazing-feature`)
5. Ouvre une Pull Request

### Standards de code
- Utilise `black` pour le formatage
- Utilise `flake8` pour le linting
- Ajoute des tests pour les nouvelles fonctionnalit√©s
- Documente les nouvelles APIs

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üÜò Support

### Documentation
- [LM Studio Documentation](https://lmstudio.ai/docs)
- [Azure DevOps Pipelines](https://docs.microsoft.com/en-us/azure/devops/pipelines/)

### Issues
- Cr√©e une issue sur GitHub pour les bugs
- Utilise les discussions pour les questions

### Contact
- Email: [votre-email@example.com]
- GitHub: [votre-username]

---

**Note** : Ce prototype est destin√© √† des fins de d√©monstration et de recherche. Pour un usage en production, des tests de s√©curit√© suppl√©mentaires et une validation approfondie sont recommand√©s.

